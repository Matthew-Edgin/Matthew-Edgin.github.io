{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthew-Edgin/Matthew-Edgin.github.io/blob/master/Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wax_Mm1sRR1"
      },
      "source": [
        "## 1. First, make some data preprocessing to clean up the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zITt04QTsRR2",
        "outputId": "f5fa7697-cb30-44be-fdc9-f13361f64443"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "from time import time\n",
        "import re\n",
        "import spacy\n",
        "!pip install markovify\n",
        "import markovify\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "!python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: markovify in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from markovify) (1.1.1)\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC7JfFS_sRR6"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'twitter_sentiment'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "tweet_df = pd.read_sql_query('select * from twitter',con=engine)\n",
        "\n",
        "# no need for an open connection, as we're only doing a single query\n",
        "engine.dispose()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tToMIgdtYYT"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "# below is necessary to avoid memory error of SpaCy\n",
        "nlp.max_length = 20000000\n",
        "\n",
        "# all the processing work is done below, so it may take a while\n",
        "twitter_doc = nlp(\" \".join(tweet_df.text))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QguiXhp4tnWH"
      },
      "source": [
        "# 2. Train Markov chain model, generate sentences, check to see if output exhibits same sentiment as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pMJWKfJuGTT",
        "outputId": "9f167a1c-1142-40cf-881c-1ed4cc5a1e53"
      },
      "source": [
        "# all the processing work is done below, so it may take a while\n",
        "twitter_negative_doc = nlp(\" \".join(tweet_df[tweet_df[\"airline_sentiment\"]==\"negative\"].text))\n",
        "\n",
        "tweet_negative_sents = \" \".join([sent.text for sent in twitter_negative_doc.sents if len(sent.text) > 1])\n",
        "\n",
        "tweet_negative_generator = markovify.Text(tweet_negative_sents, state_size = 3)\n",
        "\n",
        "# three randomly generated negative sentences\n",
        "for i in range(20):\n",
        "    print(tweet_negative_generator.make_sentence(tries=100))\n",
        "\n",
        "# three randomly-generated negative sentences of no more than 100 characters\n",
        "for i in range(20):\n",
        "    print(tweet_negative_generator.make_short_sentence(100, tries=100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I got the run around for 2 days @AmericanAir just Cancelled Flightled my ticket and is taking two months + to refund and still waiting!\n",
            "@JetBlue I just booked a flight yesterday fron TPA-DFW-AUS.\n",
            "Realizing there was more cargo to add to my pain they want me to get home to see my family until Thursday @United Your customer service line only to get to SEA!\n",
            "@AmericanAir has no idea what's going on with customer service?\n",
            "#usairwaysfail @USAirways I'm tired of this snow!\n",
            "You can see who is connecting @USAirways I packed a carry on and in Pittsburgh coming to Boston it was a problem with United.\n",
            "I have never been on a music hold for over an hour twice?\n",
            "Yet another reason why I'll never fly your airline @SouthwestAir reviewing your oversize policy.\n",
            "@united worst flights I've ever had. ground crew ignored our plane, made me miss my connection to Argentina at Houston since I'm Late Flight now?\n",
            "Going to miss my G'ma's Memorial because I didn't buy first class?\n",
            "Sadly, another booked passenger didn't make it to @LaGuardiaAir @AmericanAir The issue is the lack of communication during our awful journey on 2/21 EWR to BOS.\n",
            "#PHL @USAirways have been on hold for 4-minute fix.\n",
            "I don't understand why you have two cust service agents for a long time can you at least suggestion options for making it to my destination and not Laguardia like the app said!\n",
            "@SouthwestAir I'm running out time and patience I just want to contact someone with a question &amp; not be notified.\n",
            "But refund doesn't really makeup for the inconvenience you have put me through TWICE this month.\n",
            "#FRAUD please DM me who I can speak to regarding my travels today @AmericanAir - Hanging up on customers intentionally after one hour on phone with your team, I’m told 120 day backlog.\n",
            "Makes me want to never fly with u again.\n",
            "Three calls and 2.5 hours to get my own bag.\n",
            "Venetia Crook @SouthwestAir my wife is trying to check in to a flight from a couple weeks now.\n",
            "This has to be a better airline.\n",
            "@USAirways - been standing at the gate for half an hour.\n",
            "@USAirways literally the worst flying experience ever and they tried to have us towed.\n",
            "#ishouldhavedriven @JetBlue a 5 year old if there's a problem?\n",
            "#unhappy @USAirways No one picks up the phone - 3hrs- dead phone.\n",
            "#NeverAgain @USAirways the only time I ever fly your airline!\n",
            "@AmericanAir is the worst customer experiences I have ever experienced.\n",
            "@USAirways worst experience ever!!!! @USAirways how do you stay in business with such poor service?\n",
            "Flight 3739, missed passenger count by 5 since it was done was harsh for those affected.\n",
            "@SouthwestAir 9 hours at this airport since 11 am this morning!\n",
            "@USAirways how can a plane scheduled to come in on time and the website is not working.\n",
            "@AmericanAir thx for the note.\n",
            "@united so 8 hotels for 32 people but feel like we are about to get going, finally!\n",
            "Going to miss our connection to FLL so yes hotels were necessary @united can you help me rebook?\n",
            "Can you let me know about this?\n",
            "@AmericanAir I am still in the queue ...\n",
            "@united friends been sitting in Philly for hours.\n",
            "However at gate they rebooked me to a person and not be put on hold for over 3 hours.\n",
            "@AmericanAir AA2334 Second week in a row with missing luggage.\n",
            "@AmericanAir Need to hold or get a hotel voucher, but had to take off - no explanations or sorry.\n",
            "#sorude @USAirways , I am rerouted to Dulles.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gfS721luVjW"
      },
      "source": [
        "So I focused on negative sentiment here and the tweets on display are definently showing negative sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpBuKcf6uf7j"
      },
      "source": [
        "# 3. Repeat previous task but with positive sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyyp9tylunvk",
        "outputId": "d0c80171-7200-48cb-9156-dc21ea43bf64"
      },
      "source": [
        "# all the processing work is done below, so it may take a while\n",
        "twitter_positive_doc = nlp(\" \".join(tweet_df[tweet_df[\"airline_sentiment\"]==\"positive\"].text))\n",
        "\n",
        "tweet_positive_sents = \" \".join([sent.text for sent in twitter_positive_doc.sents if len(sent.text) > 1])\n",
        "\n",
        "tweet_positive_generator = markovify.Text(tweet_positive_sents, state_size = 3)\n",
        "\n",
        "# three randomly generated sentences\n",
        "for i in range(20):\n",
        "    print(tweet_positive_generator.make_sentence(tries=100))\n",
        "\n",
        "# three randomly-generated sentences of no more than 100 characters\n",
        "for i in range(20):\n",
        "    print(tweet_positive_generator.make_short_sentence(100, tries=100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He ought to give a shout out to the flight #4386 crew for taking amazing care of us at the PHX airport. http://t.co/HG7vEqhGHy Great management of @USAirways twitter account.\n",
            "Excited to fly with you again!\n",
            "Finally, I get to go to the #DestinationDragons concert Vegas @Imaginedragons So awesome! http://t.co/G9b6e0a2sZ @SouthwestAir Yes!\n",
            "I hope you expand to other airports soon so I can have a friend travel next time!\n",
            "It was wind and I was seated with my daughter!\n",
            "Excited to get home today.\n",
            "Just have never seen before!\n",
            "Was able to get my stranded family home.\n",
            "@USAirways thank you for the accommodations!\n",
            "@SouthwestAir - I just had a great experience with your staff at DIA last night.\n",
            "@SouthwestAir thanks for getting me home amongst many other Cancelled Flightlations.\n",
            "@united I left my iPad on a plane, filled out a claim and hope to do so more!\n",
            "I was very Late Flight for my connecting flight at EWR despite a 2+ hour layover.\n",
            "@AmericanAir thanks to AA / DART for getting me to Orlando early #happiness @JetBlue flight from JFK-SFO was pure awesomeness.\n",
            "Will be easier to change flights when weathers bad @JetBlue @JetBlue thanks so much!! ❤️✨ very relaxing flight!\n",
            "Thanks for the follow up.\n",
            "@united went to Customer Service kiosk and they were traveling as guests of a mileage plus member using that members miles.\n",
            "@SouthwestAir is hosting an @TheAcademy party in the terminal and now we're taking off.\n",
            "You will help us get back to DFW @AmericanAir Will do.\n",
            "@AmericanAir keep up the good work folks, this is where they keep me for the night.. http://t.co/avRTOWTyzk @united thanks for moving my dad on to my my mom's flight.\n",
            "That's the best flight ever!\n",
            "@united I left my iPad on a plane, filled out a claim and hope to do so more!\n",
            "@SouthwestAir @DeltaPoints hey at least you guys are great thanks for everything!\n",
            "You guys are the best!\n",
            "2 mths waiting @AmericanAir to speak to someone things got fixed very quick.\n",
            "@SouthwestAir - just talking to customer service and focus @JetBlue thanks for your prompt response.\n",
            "NO to @Carrieunderwood @VirginAmerica you know what time that lane opens at Logan?\n",
            "Appreciate the response @united thank you Very quick!\n",
            "#patience #luvswa Never got to the airport the rebooked ticket was refunded.\n",
            "@united you guys are the best.\n",
            "Now we just need to be outside.\n",
            "&amp ; one last question do you have any new routes planned this year for Newark.\n",
            "They did a great job.\n",
            "#VAbeatsJblue @virginamerica you ROCK for making it so I can have a friend travel next time!\n",
            "@VirginAmerica I &lt;3 pretty graphics. so much better now!!! @SouthwestAir Fantastic!\n",
            "^JH ” @united thanks for the response as always, good or bad.\n",
            "@SouthwestAir - I just had a great flight @SouthwestAir thanks!\n",
            "Two weeks Late Flightr they found it and shipped it back.\n",
            "Makes me laugh every time, AND now I want to fly with you I'm delighted.\n",
            "Thx @AmericanAir 1138 got us to DIA on time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlMCO_L9uwt_"
      },
      "source": [
        "This time we see more positive sentiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdneVh_au03D"
      },
      "source": [
        "# 4. Do the same as previous tasks but this time using all tweets to generate random sentences. comment on yourr observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKxphidWvCpH",
        "outputId": "4625995c-f685-4b37-fa2a-ab33e2ab5fd3"
      },
      "source": [
        "# all the processing work is done below, so it may take a while\n",
        "twitter_doc = nlp(\" \".join(tweet_df.text))\n",
        "\n",
        "tweet_sents = \" \".join([sent.text for sent in twitter_doc.sents if len(sent.text) > 1])\n",
        "\n",
        "tweet_generator = markovify.Text(tweet_sents, state_size = 3)\n",
        "\n",
        "# three randomly generated sentences\n",
        "for i in range(20):\n",
        "    print(tweet_generator.make_sentence(tries=100))\n",
        "\n",
        "# three randomly-generated sentences of no more than 100 characters\n",
        "for i in range(20):\n",
        "    print(tweet_generator.make_short_sentence(100, tries=100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO MORE @JetBlue - I look forward to having both of you on board.\n",
            "Trying to get through by phone and don't see any option and made typo when logging in.\n",
            "I would I have lost my luggage and take my son to Imagine Dragons in Provo Saturday night.\n",
            "On the phone for US Air in philly to talk to someone on the phone.\n",
            "I've been tryin for 3 days and it's still frozen.\n",
            "Whenever I see it, I want to speak with a live person.\n",
            "@SouthwestAir #BNA @SouthwestAir - STL-BOS flight today was Cancelled Flightled yet but assuming it will be?\n",
            "Read my previous tweets and get some additional phone reps to do their jobs @AmericanAir work would be much more beneficial.\n",
            "RT @JetBlue: Our fleet's on fleek. http://t.co/2z3hGqPRSG @JetBlue any info on delays at SFO tomorrow due to low clouds?\n",
            "#slow-fi @SouthwestAir About time...and just in time for work this morning DEN-DFW... didn't have to check my bag and through the TSA checkpoint, I guarantee I will be calling corporate!\n",
            "Now I'm back home and have to incur overnight costs in a connecting city.\n",
            "We are now 20 min Late Flight @SouthwestAir oh, ok!\n",
            "@SouthwestAir @SMiles1307 over two hours on hold.\n",
            "@USAirways i tried it but doesnt help very much and Reservation seems to be broken for me https://t.co/2pUJvCElNg @VirginAmerica can't check in or can I do it at the airport?\n",
            "Looking forward to the response.\n",
            "@united you have to follow you and can't DM because u need to tell passengers where to go to work tomorrow am.\n",
            "#pleasehelp @AmericanAir I need to be in Boston by Monday.\n",
            "@USAirways Why can't I get anyone on the phone is 40 minutes... can you help?\n",
            "@SouthwestAir #BNA @SouthwestAir - STL-BOS flight today was Cancelled Flightled yesterday &amp; I was on phone with your team, I’m told 120 day backlog.\n",
            "Can't change my flight that was Cancelled Flightled from Dallas to Austin.\n",
            "@JetBlue so yesterday a flight I bought went up!\n",
            "@USAirways &amp; also that I was ON THE PLANE and at the gate??? Jax2BNA.\n",
            "I got thru on the phone to get him a pass to the Club.\n",
            "Your phone tree just hangs up and your agents on the ground and in the air by now.\n",
            "@AmericanAir I FOUND MY FOOTAGE!! :D I am so mad!!! @AmericanAir ok thank you!\n",
            "I follow you now, so you can DM me back.\n",
            "@JetBlue will you Cancelled Flight my connecting flight @USAirways Good grief!\n",
            "How do we get a plane to be refueled.\n",
            "I know how to treat customers.\n",
            "Plus you don't follow me @AmericanAir No, had already waited an hour for an update.\n",
            "Need to get on a flight about 3 months ago.\n",
            "@AmericanAir To add, I have to sign on to the bag....\n",
            "@AmericanAir i do not want to wait their turn can get a printed one for my records?\n",
            "They have no idea when would be a heat wave, so enjoy the warmth!\n",
            "@AmericanAir my wife was on a flight with you guys and hope to do so more!\n",
            "I know you guys are lucky I love you guys, but pls get some direct routes LAS to AUS!\n",
            "#Fail @united still sitting here waiting for a reply to an email.\n",
            "Going to miss our connection to pns?\n",
            "Send me an email to share my seat with no notice.\n",
            "Thank y'all for being an amazing airline who knows how to pamper customers they strand abroad.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_9BStYRvYHf"
      },
      "source": [
        "This time there is a mix of positive and negative sentiments."
      ]
    }
  ]
}